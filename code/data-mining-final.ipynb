{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9671835,"sourceType":"datasetVersion","datasetId":5910494},{"sourceId":9671860,"sourceType":"datasetVersion","datasetId":5910512}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms, models\nfrom transformers import RobertaTokenizer, RobertaModel\nimport pandas as pd\nfrom PIL import Image\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:11:45.004161Z","iopub.execute_input":"2024-11-22T11:11:45.004506Z","iopub.status.idle":"2024-11-22T11:11:50.824273Z","shell.execute_reply.started":"2024-11-22T11:11:45.004473Z","shell.execute_reply":"2024-11-22T11:11:50.823507Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport pickle\n\n# Load the Excel file\ndf = pd.read_excel('/kaggle/input/cyber-excel/Copy of Cyberbully_corrected_emotion_sentiment.xlsx')\ndf = df.drop(columns=['Unnamed: 10', 'Unnamed: 11'])\n# Display the first few rows to ensure it is loaded correctly\n# print(df)\n\ndf_cleaned = df.dropna()\ndf=df_cleaned\n# print(df)\nimport os\nimport pandas as pd\n\n# Assuming your DataFrame is called df and contains the 'img_id' column\n# Assuming image paths are in a directory (img_dir) and filenames correspond to 'img_id'\n\nimg_dir = \"/kaggle/input/multibully/bully_data\"\n\n# Define a function to check if the image size is zero\ndef is_zero_size(img_id, img_dir):\n    img_path = os.path.join(img_dir, img_id)\n    return os.path.exists(img_path) and os.path.getsize(img_path) == 0\n\n# Filter out rows with zero-size images\ndf['is_zero_size'] = df['Img_Name'].apply(lambda img_id: is_zero_size(img_id, img_dir))\ndf_filtered = df[df['is_zero_size'] == False].drop(columns='is_zero_size')\n\n# Now, df_filtered contains only rows with non-zero-size images\n# print(df_filtered)\ndf=df_filtered\ndf_cleaned = df[df['Img_Name'] != '2644.jpg']\ndf=df_cleaned\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:11:50.825972Z","iopub.execute_input":"2024-11-22T11:11:50.826365Z","iopub.status.idle":"2024-11-22T11:11:55.978291Z","shell.execute_reply.started":"2024-11-22T11:11:50.826337Z","shell.execute_reply":"2024-11-22T11:11:55.977603Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:11:55.979418Z","iopub.execute_input":"2024-11-22T11:11:55.979967Z","iopub.status.idle":"2024-11-22T11:11:55.986462Z","shell.execute_reply.started":"2024-11-22T11:11:55.979921Z","shell.execute_reply":"2024-11-22T11:11:55.985502Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(3078, 10)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:11:55.988103Z","iopub.execute_input":"2024-11-22T11:11:55.988360Z","iopub.status.idle":"2024-11-22T11:11:56.007101Z","shell.execute_reply.started":"2024-11-22T11:11:55.988336Z","shell.execute_reply":"2024-11-22T11:11:56.006438Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:11:56.008055Z","iopub.execute_input":"2024-11-22T11:11:56.008298Z","iopub.status.idle":"2024-11-22T11:11:56.028191Z","shell.execute_reply.started":"2024-11-22T11:11:56.008274Z","shell.execute_reply":"2024-11-22T11:11:56.027370Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"  Img_Name                                           Img_Text Img_Text_Label  \\\n0    0.jpg  Shivam @shivamishraa Girls be named naina and ...          Bully   \n\n  Img_Label Text_Label Sentiment  Emotion Sarcasm      Harmful_Score  \\\n0  Nonbully      Bully  Negative  Disgust     Yes  Partially-Harmful   \n\n       Target  \n0  Individual  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Img_Name</th>\n      <th>Img_Text</th>\n      <th>Img_Text_Label</th>\n      <th>Img_Label</th>\n      <th>Text_Label</th>\n      <th>Sentiment</th>\n      <th>Emotion</th>\n      <th>Sarcasm</th>\n      <th>Harmful_Score</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.jpg</td>\n      <td>Shivam @shivamishraa Girls be named naina and ...</td>\n      <td>Bully</td>\n      <td>Nonbully</td>\n      <td>Bully</td>\n      <td>Negative</td>\n      <td>Disgust</td>\n      <td>Yes</td>\n      <td>Partially-Harmful</td>\n      <td>Individual</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"class MemeDataset(Dataset):\n    def __init__(self, dataframe, transform):\n        self.dataframe = dataframe\n        self.transform = transform\n        self.tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n        self.img_folder = '/kaggle/input/multibully/bully_data'\n        # Define label mappings\n        self.text_label_mapping = {\n            \"Bully\": 1,\n            \"Nonbully\": 0\n        }\n        \n        self.sentiment_mapping = {\n            \"Positive\":1,\n            \"Neutral\": 0,\n            \"Negative\": 2\n        }\n        \n        self.emotion_mapping = {\n            \"Disgust\": 0,\n            \"Ridicule\": 1,\n            \"Sadness\": 2,\n            \"Surprise\": 3,\n            \"Anticipation\": 4,\n            \"Angry\": 5,\n            \"Happiness\": 6,\n            \"Other\": 7,\n            \"Trust\": 8,\n            \"Fear\": 9\n        }\n        \n        self.sarcasm_mapping = {\n            \"Yes\": 1,\n            \"No\": 0\n        }\n        \n        self.harmful_score_mapping = {\n            \"Harmless\": 0,\n            \"Partially-Harmful\": 1,\n            \"Very-Harmful\": 2\n        }\n        \n        self.target_mapping = {\n            \"Individual\": 0,\n            \"Society\": 1,\n            \"Organization\": 2,\n            \"Community\": 3\n        }\n    \n    def __len__(self):\n        return len(self.dataframe)\n    \n    def __getitem__(self, idx):\n        # Load image\n        img_name = self.dataframe.iloc[idx]['Img_Name']\n        img_path = os.path.join(self.img_folder, img_name)\n        image = Image.open(img_path).convert('RGB')\n        image = self.transform(image)\n        \n        # Load and tokenize text\n        text = self.dataframe.iloc[idx]['Img_Text']\n        inputs = self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n        \n        # Get labels and apply mappings\n        sentiment_label = torch.tensor(self.sentiment_mapping[self.dataframe.iloc[idx]['Sentiment']], dtype=torch.long)\n        emotion_label = torch.tensor(self.emotion_mapping[self.dataframe.iloc[idx]['Emotion']], dtype=torch.long)\n        sarcasm_label = torch.tensor(self.sarcasm_mapping[self.dataframe.iloc[idx]['Sarcasm']], dtype=torch.float)  # Binary sarcasm\n        bully_label = torch.tensor(self.text_label_mapping[self.dataframe.iloc[idx]['Img_Label']], dtype=torch.long)  # Bully detection\n        harmful_score_label = torch.tensor(self.harmful_score_mapping[self.dataframe.iloc[idx]['Harmful_Score']], dtype=torch.long)\n        target_label = torch.tensor(self.target_mapping[self.dataframe.iloc[idx]['Target']], dtype=torch.long)\n        \n        return image, inputs['input_ids'].squeeze(), inputs['attention_mask'].squeeze(), sentiment_label, emotion_label, sarcasm_label, bully_label, harmful_score_label, target_label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:11:56.029216Z","iopub.execute_input":"2024-11-22T11:11:56.029643Z","iopub.status.idle":"2024-11-22T11:11:56.039746Z","shell.execute_reply.started":"2024-11-22T11:11:56.029617Z","shell.execute_reply":"2024-11-22T11:11:56.038803Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class Image_text(nn.Module):\n    def __init__(self):\n        super(Image_text, self).__init__()\n        \n        # Visual branch (CNN)\n        self.resnet = models.resnet50(pretrained=True)\n        self.resnet.fc = nn.Identity()  # Remove the final classification layer\n        \n        # Textual branch (RoBERTa)\n        self.roberta = RobertaModel.from_pretrained('roberta-base')\n        \n        # Shared fully connected layers\n        self.fc_shared = nn.Sequential(\n            nn.Linear(2048 + 768, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n        \n        # Task-specific heads\n        self.sentiment_head = nn.Linear(512, 3)  # Sentiment: 3 classes\n        self.emotion_head = nn.Linear(512, 10)    # Emotion: 6 classes\n        self.sarcasm_head = nn.Linear(512, 1)    # Sarcasm: binary classification\n        self.bully_head = nn.Linear(512, 2)      # Cyberbullying: 2 classes\n        self.harmful_head = nn.Linear(512, 3)\n        self.target_head = nn.Linear(512, 4)\n    def forward(self, image, text_input_ids, text_attention_mask):\n        # Visual features\n        img_features = self.resnet(image)\n        \n        # Textual features\n        text_outputs = self.roberta(input_ids=text_input_ids, attention_mask=text_attention_mask)\n        text_features = text_outputs.pooler_output\n        \n        # Concatenate the visual and textual features\n        combined_features = torch.cat((img_features, text_features), dim=1)\n        \n        # Shared layers\n        shared_out = self.fc_shared(combined_features)\n        \n        # Task-specific outputs\n        sentiment_out = self.sentiment_head(shared_out)\n        emotion_out = self.emotion_head(shared_out)\n        sarcasm_out = torch.sigmoid(self.sarcasm_head(shared_out))\n        bully_out = self.bully_head(shared_out)\n        harmful_out = self.harmful_head(shared_out)\n        target_out = self.target_head(shared_out)\n        \n        return sentiment_out, emotion_out, sarcasm_out, bully_out, harmful_out, target_out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:11:56.040676Z","iopub.execute_input":"2024-11-22T11:11:56.040910Z","iopub.status.idle":"2024-11-22T11:11:56.053595Z","shell.execute_reply.started":"2024-11-22T11:11:56.040888Z","shell.execute_reply":"2024-11-22T11:11:56.052723Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class Image_text_emotion(nn.Module):\n    def __init__(self):\n        super(Image_text_emotion, self).__init__()\n        \n        # Visual branch (CNN)\n        self.resnet = models.resnet50(pretrained=True)\n        self.resnet.fc = nn.Identity()  # Remove the final classification layer\n        \n        # Textual branch (RoBERTa)\n        self.roberta = RobertaModel.from_pretrained('roberta-base')\n        \n        # Shared fully connected layers\n        self.fc_shared = nn.Sequential(\n            nn.Linear(2048 + 768, 512),  # Concatenation of visual and textual features\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n        \n        # Task-specific heads\n        self.sentiment_head = nn.Linear(512, 3)  # Sentiment: 3 classes\n        self.emotion_head = nn.Linear(512, 10)  # Emotion: 10 classes\n        self.sarcasm_head = nn.Linear(512, 1)  # Sarcasm: binary classification\n        # self.bully_head = nn.Linear(512, 2)  # Bully: binary classification\n        self.bully_fc = nn.Sequential(\n            nn.Linear(10 + 512, 256),  # Input: all task outputs + shared features\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 2)  # 2 classes for bully\n        )\n        # self.harmful_head = nn.Linear(512, 3)  # Harmful score: 3 classes\n        self.harmful_fc = nn.Sequential(\n            nn.Linear(10 + 512, 256),  # Input: all task outputs + shared features\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 3)  # 3 classes for harmful\n        )\n        # Final target head\n        self.target_fc = nn.Sequential(\n            nn.Linear(10 + 512, 256),  # Input: all task outputs + shared features\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 4)  # 4 classes for Target\n        )\n        \n    def forward(self, image, text_input_ids, text_attention_mask):\n        # Visual features\n        img_features = self.resnet(image)\n        \n        # Textual features\n        text_outputs = self.roberta(input_ids=text_input_ids, attention_mask=text_attention_mask)\n        text_features = text_outputs.pooler_output\n        \n        # Concatenate the visual and textual features\n        combined_features = torch.cat((img_features, text_features), dim=1)\n        \n        # Shared features\n        shared_out = self.fc_shared(combined_features)\n        \n        # Task-specific predictions\n        sentiment_out = self.sentiment_head(shared_out)\n        emotion_out = self.emotion_head(shared_out)\n        sarcasm_out = torch.sigmoid(self.sarcasm_head(shared_out))  # Binary\n        # bully_out = self.bully_head(shared_out)\n        # harmful_out = self.harmful_head(shared_out)\n        \n        # Concatenate all task outputs with shared features for target prediction\n        aux_features = torch.cat((\n            emotion_out,\n            shared_out  # Shared features\n        ), dim=1)\n        \n        # Final target prediction\n        bully_out = self.bully_fc(aux_features)\n        harmful_out = self.harmful_fc(aux_features)\n        target_out = self.target_fc(aux_features)\n        \n        return sentiment_out, emotion_out, sarcasm_out, bully_out, harmful_out, target_out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:11:56.054824Z","iopub.execute_input":"2024-11-22T11:11:56.055202Z","iopub.status.idle":"2024-11-22T11:11:56.071106Z","shell.execute_reply.started":"2024-11-22T11:11:56.055164Z","shell.execute_reply":"2024-11-22T11:11:56.070304Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class Image_text_sentiment(nn.Module):\n    def __init__(self):\n        super(Image_text_sentiment, self).__init__()\n        \n        # Visual branch (CNN)\n        self.resnet = models.resnet50(pretrained=True)\n        self.resnet.fc = nn.Identity()  # Remove the final classification layer\n        \n        # Textual branch (RoBERTa)\n        self.roberta = RobertaModel.from_pretrained('roberta-base')\n        \n        # Shared fully connected layers\n        self.fc_shared = nn.Sequential(\n            nn.Linear(2048 + 768, 512),  # Concatenation of visual and textual features\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n        \n        # Task-specific heads\n        self.sentiment_head = nn.Linear(512, 3)  # Sentiment: 3 classes\n        self.emotion_head = nn.Linear(512, 10)  # Emotion: 10 classes\n        self.sarcasm_head = nn.Linear(512, 1)  # Sarcasm: binary classification\n        # self.bully_head = nn.Linear(512, 2)  # Bully: binary classification\n        self.bully_fc = nn.Sequential(\n            nn.Linear(3 + 512, 256),  # Input: all task outputs + shared features\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 2)  # 2 classes for bully\n        )\n        # self.harmful_head = nn.Linear(512, 3)  # Harmful score: 3 classes\n        self.harmful_fc = nn.Sequential(\n            nn.Linear(3 + 512, 256),  # Input: all task outputs + shared features\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 3)  # 3 classes for harmful\n        )\n        # Final target head\n        self.target_fc = nn.Sequential(\n            nn.Linear(3 + 512, 256),  # Input: all task outputs + shared features\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 4)  # 4 classes for Target\n        )\n        \n    def forward(self, image, text_input_ids, text_attention_mask):\n        # Visual features\n        img_features = self.resnet(image)\n        \n        # Textual features\n        text_outputs = self.roberta(input_ids=text_input_ids, attention_mask=text_attention_mask)\n        text_features = text_outputs.pooler_output\n        \n        # Concatenate the visual and textual features\n        combined_features = torch.cat((img_features, text_features), dim=1)\n        \n        # Shared features\n        shared_out = self.fc_shared(combined_features)\n        \n        # Task-specific predictions\n        sentiment_out = self.sentiment_head(shared_out)\n        emotion_out = self.emotion_head(shared_out)\n        sarcasm_out = torch.sigmoid(self.sarcasm_head(shared_out))  # Binary\n        # bully_out = self.bully_head(shared_out)\n        # harmful_out = self.harmful_head(shared_out)\n        \n        # Concatenate all task outputs with shared features for target prediction\n        aux_features = torch.cat((\n            sentiment_out,\n            shared_out  # Shared features\n        ), dim=1)\n        \n        # Final target prediction\n        bully_out = self.bully_fc(aux_features)\n        harmful_out = self.harmful_fc(aux_features)\n        target_out = self.target_fc(aux_features)\n        \n        return sentiment_out, emotion_out, sarcasm_out, bully_out, harmful_out, target_out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:11:56.071976Z","iopub.execute_input":"2024-11-22T11:11:56.072262Z","iopub.status.idle":"2024-11-22T11:11:56.086060Z","shell.execute_reply.started":"2024-11-22T11:11:56.072221Z","shell.execute_reply":"2024-11-22T11:11:56.085331Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class Image_text_emotion_sentiment(nn.Module):\n    def __init__(self):\n        super(Image_text_emotion_sentiment, self).__init__()\n        \n        # Visual branch (CNN)\n        self.resnet = models.resnet50(pretrained=True)\n        self.resnet.fc = nn.Identity()  # Remove the final classification layer\n        \n        # Textual branch (RoBERTa)\n        self.roberta = RobertaModel.from_pretrained('roberta-base')\n        \n        # Shared fully connected layers\n        self.fc_shared = nn.Sequential(\n            nn.Linear(2048 + 768, 512),  # Concatenation of visual and textual features\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n        \n        # Task-specific heads\n        self.sentiment_head = nn.Linear(512, 3)  # Sentiment: 3 classes\n        self.emotion_head = nn.Linear(512, 10)  # Emotion: 10 classes\n        self.sarcasm_head = nn.Linear(512, 1)  # Sarcasm: binary classification\n        # self.bully_head = nn.Linear(512, 2)  # Bully: binary classification\n        self.bully_fc = nn.Sequential(\n            nn.Linear(10 + 3 + 512, 256),  # Input: all task outputs + shared features\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 2)  # 2 classes for bully\n        )\n        # self.harmful_head = nn.Linear(512, 3)  # Harmful score: 3 classes\n        self.harmful_fc = nn.Sequential(\n            nn.Linear(10 + 3+ 512, 256),  # Input: all task outputs + shared features\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 3)  # 3 classes for harmful\n        )\n        # Final target head\n        self.target_fc = nn.Sequential(\n            nn.Linear(10 + 3 +  512, 256),  # Input: all task outputs + shared features\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 4)  # 4 classes for Target\n        )\n        \n    def forward(self, image, text_input_ids, text_attention_mask):\n        # Visual features\n        img_features = self.resnet(image)\n        \n        # Textual features\n        text_outputs = self.roberta(input_ids=text_input_ids, attention_mask=text_attention_mask)\n        text_features = text_outputs.pooler_output\n        \n        # Concatenate the visual and textual features\n        combined_features = torch.cat((img_features, text_features), dim=1)\n        \n        # Shared features\n        shared_out = self.fc_shared(combined_features)\n        \n        # Task-specific predictions\n        sentiment_out = self.sentiment_head(shared_out)\n        emotion_out = self.emotion_head(shared_out)\n        sarcasm_out = torch.sigmoid(self.sarcasm_head(shared_out))  # Binary\n        # bully_out = self.bully_head(shared_out)\n        # harmful_out = self.harmful_head(shared_out)\n        \n        # Concatenate all task outputs with shared features for target prediction\n        aux_features = torch.cat((\n            emotion_out,\n            sentiment_out,\n            shared_out  # Shared features\n        ), dim=1)\n        \n        # Final target prediction\n        bully_out = self.bully_fc(aux_features)\n        harmful_out = self.harmful_fc(aux_features)\n        target_out = self.target_fc(aux_features)\n        \n        return sentiment_out, emotion_out, sarcasm_out, bully_out, harmful_out, target_out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:11:56.088760Z","iopub.execute_input":"2024-11-22T11:11:56.089011Z","iopub.status.idle":"2024-11-22T11:11:56.102356Z","shell.execute_reply.started":"2024-11-22T11:11:56.088989Z","shell.execute_reply":"2024-11-22T11:11:56.101638Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from torch.utils.data import random_split\nfrom sklearn.metrics import accuracy_score, f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:11:56.103614Z","iopub.execute_input":"2024-11-22T11:11:56.103932Z","iopub.status.idle":"2024-11-22T11:11:56.593390Z","shell.execute_reply.started":"2024-11-22T11:11:56.103897Z","shell.execute_reply":"2024-11-22T11:11:56.592738Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Create the dataset and dataloader\ndataset = MemeDataset(df, transform=transform)\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n# Create data loaders\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n\n# dataloader = DataLoader(dataset, batch_size=16, shuffle=True)  # Adjust batch size as needed\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:11:56.594267Z","iopub.execute_input":"2024-11-22T11:11:56.594674Z","iopub.status.idle":"2024-11-22T11:11:58.242334Z","shell.execute_reply.started":"2024-11-22T11:11:56.594649Z","shell.execute_reply":"2024-11-22T11:11:58.241762Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4ef42e73fb04ecb90973e29fb46967f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47d4d91299b54012acbcb4882876b1b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83938801266040de9e2fccbbe7568640"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0cf76e3bba94a22919f31183858e13c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21cbe3f3262c461fb568e70b9965579e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## Image and text","metadata":{}},{"cell_type":"code","source":"# Initialize the model and move it to the GPU\nmodel= Image_text()\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(model)  # Use DataParallel if multiple GPUs are available\nmodel.to(device) \noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n# Loss functions\nloss_fn_sentiment = nn.CrossEntropyLoss().to(device)\nloss_fn_emotion = nn.CrossEntropyLoss().to(device)\nloss_fn_sarcasm = nn.BCEWithLogitsLoss().to(device)\nloss_fn_bully = nn.CrossEntropyLoss().to(device)\nloss_fn_harmful_score = nn.CrossEntropyLoss().to(device)\nloss_fn_target = nn.CrossEntropyLoss().to(device)\n\n# Training loop\nfor epoch in range(15):  # Set epochs accordingly\n    model.train()\n    \n    total_loss = 0  # Initialize total loss for the epoch\n    \n    for images, text_input_ids, text_attention_mask, sentiment_labels, emotion_labels, sarcasm_labels, bully_labels, harmful_score_labels, target_labels in train_dataloader:\n        # Move data to the GPU\n    # for images, text_input_ids, text_attention_mask, bully_labels in train_dataloader:\n  \n        images = images.to(device)\n        text_input_ids = text_input_ids.to(device)\n        text_attention_mask = text_attention_mask.to(device)\n        sentiment_labels = sentiment_labels.to(device)\n        emotion_labels = emotion_labels.to(device)\n        sarcasm_labels = sarcasm_labels.to(device)\n        bully_labels = bully_labels.to(device)\n        harmful_score_labels = harmful_score_labels.to(device)\n        target_labels = target_labels.to(device)\n        \n        optimizer.zero_grad()  # Clear gradients at the start of each batch\n        \n        # Forward pass\n        sentiment_out, emotion_out, sarcasm_out, bully_out, harmful_score_out, target_out = model(images, text_input_ids, text_attention_mask)\n        \n        # Compute loss for each task\n        loss_sentiment = loss_fn_sentiment(sentiment_out, sentiment_labels)\n        loss_emotion = loss_fn_emotion(emotion_out, emotion_labels)\n        loss_sarcasm = loss_fn_sarcasm(sarcasm_out.squeeze(), sarcasm_labels.float())  # Squeeze if necessary\n        loss_bully = loss_fn_bully(bully_out, bully_labels)\n        loss_harmful_score = loss_fn_harmful_score(harmful_score_out, harmful_score_labels)\n        loss_target = loss_fn_target(target_out, target_labels)\n        \n        # Total loss (sum or weigh the losses as needed)\n        total_loss_batch = loss_sentiment + loss_emotion + loss_sarcasm + loss_bully + loss_harmful_score + loss_target\n        \n        # Backward pass and optimization\n        total_loss_batch.backward()\n        optimizer.step()  # Update model parameters\n        \n        total_loss += total_loss_batch.item()  # Accumulate loss for the epoch\n\n    # Optionally clear cache at the end of each epoch\n    torch.cuda.empty_cache()  \n    \n    # Print the average loss for the epoch\n    avg_loss = total_loss / len(train_dataloader)\n    print(f'Epoch {epoch}, Average Loss: {avg_loss:.4f}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:11:58.243376Z","iopub.execute_input":"2024-11-22T11:11:58.243746Z","iopub.status.idle":"2024-11-22T11:31:05.898971Z","shell.execute_reply.started":"2024-11-22T11:11:58.243710Z","shell.execute_reply":"2024-11-22T11:31:05.898061Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 208MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cb14321914d433589f9f0c239833dcd"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0, Average Loss: 4.6428\nEpoch 1, Average Loss: 4.3181\nEpoch 2, Average Loss: 3.9292\nEpoch 3, Average Loss: 3.4435\nEpoch 4, Average Loss: 2.9588\nEpoch 5, Average Loss: 2.6406\nEpoch 6, Average Loss: 2.2862\nEpoch 7, Average Loss: 2.0696\nEpoch 8, Average Loss: 1.8450\nEpoch 9, Average Loss: 1.7172\nEpoch 10, Average Loss: 1.6026\nEpoch 11, Average Loss: 1.5782\nEpoch 12, Average Loss: 1.4626\nEpoch 13, Average Loss: 1.3972\nEpoch 14, Average Loss: 1.3827\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:52:33.299307Z","iopub.execute_input":"2024-11-22T11:52:33.299694Z","iopub.status.idle":"2024-11-22T11:52:33.304066Z","shell.execute_reply.started":"2024-11-22T11:52:33.299663Z","shell.execute_reply":"2024-11-22T11:52:33.303027Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Import required libraries (if not already done)\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, f1_score\n\n# Validation phase\nmodel.eval()  # Set model to evaluation mode\ntotal_val_loss = 0\n\n# Initialize lists to store true and predicted labels for each task\nall_labels_bully = []\nall_preds_bully = []\n\nall_labels_sentiment = []\nall_preds_sentiment = []\n\nall_labels_emotion = []\nall_preds_emotion = []\n\nall_labels_sarcasm = []\nall_preds_sarcasm = []\n\nall_labels_harmful_score = []\nall_preds_harmful_score = []\n\nall_labels_target = []\nall_preds_target = []\n\nwith torch.no_grad():  # Disable gradient calculation\n    for images, text_input_ids, text_attention_mask, sentiment_labels, emotion_labels, sarcasm_labels, bully_labels, harmful_score_labels, target_labels in val_dataloader:\n        # Move data to the GPU\n        images = images.to(device)\n        text_input_ids = text_input_ids.to(device)\n        text_attention_mask = text_attention_mask.to(device)\n        sentiment_labels = sentiment_labels.to(device)\n        emotion_labels = emotion_labels.to(device)\n        sarcasm_labels = sarcasm_labels.to(device)\n        bully_labels = bully_labels.to(device)\n        harmful_score_labels = harmful_score_labels.to(device)\n        target_labels = target_labels.to(device)\n\n        # Forward pass\n        sentiment_out, emotion_out, sarcasm_out, bully_out, harmful_score_out, target_out = model(images, text_input_ids, text_attention_mask)\n\n        # Compute loss for each task\n        loss_sentiment = loss_fn_sentiment(sentiment_out, sentiment_labels)\n        loss_emotion = loss_fn_emotion(emotion_out, emotion_labels)\n        loss_sarcasm = loss_fn_sarcasm(sarcasm_out.squeeze(), sarcasm_labels.float())\n        loss_bully = loss_fn_bully(bully_out, bully_labels)\n        loss_harmful_score = loss_fn_harmful_score(harmful_score_out, harmful_score_labels)\n        loss_target = loss_fn_target(target_out, target_labels)\n\n        # Total loss\n        total_val_loss += (loss_sentiment + loss_emotion + loss_sarcasm + loss_bully + loss_harmful_score + loss_target).item()\n\n        # Get predictions for each task\n        _, predicted_sentiment = torch.max(sentiment_out, 1)\n        _, predicted_emotion = torch.max(emotion_out, 1)\n        _, predicted_sarcasm = torch.max(sarcasm_out, 1)\n        _, predicted_bully = torch.max(bully_out, 1)\n        _, predicted_harmful_score = torch.max(harmful_score_out, 1)  # Assuming multi-class\n        _, predicted_target = torch.max(target_out, 1)  # Assuming multi-class\n\n        # Collect true and predicted labels for each task\n        all_labels_sentiment.append(sentiment_labels.cpu().numpy())\n        all_preds_sentiment.append(predicted_sentiment.cpu().numpy())\n\n        all_labels_emotion.append(emotion_labels.cpu().numpy())\n        all_preds_emotion.append(predicted_emotion.cpu().numpy())\n\n        all_labels_sarcasm.append(sarcasm_labels.cpu().numpy())\n        all_preds_sarcasm.append(predicted_sarcasm.cpu().numpy())\n\n        all_labels_bully.append(bully_labels.cpu().numpy())\n        all_preds_bully.append(predicted_bully.cpu().numpy())\n\n        all_labels_harmful_score.append(harmful_score_labels.cpu().numpy())\n        all_preds_harmful_score.append(predicted_harmful_score.cpu().numpy())\n\n        all_labels_target.append(target_labels.cpu().numpy())\n        all_preds_target.append(predicted_target.cpu().numpy())\n\navg_val_loss = total_val_loss / len(val_dataloader)\n\n# Flatten lists for each task\nall_labels_bully = np.concatenate(all_labels_bully)\nall_preds_bully = np.concatenate(all_preds_bully)\n\nall_labels_sentiment = np.concatenate(all_labels_sentiment)\nall_preds_sentiment = np.concatenate(all_preds_sentiment)\n\nall_labels_emotion = np.concatenate(all_labels_emotion)\nall_preds_emotion = np.concatenate(all_preds_emotion)\n\nall_labels_sarcasm = np.concatenate(all_labels_sarcasm)\nall_preds_sarcasm = np.concatenate(all_preds_sarcasm)\n\nall_labels_harmful_score = np.concatenate(all_labels_harmful_score)\nall_preds_harmful_score = np.concatenate(all_preds_harmful_score)\n\nall_labels_target = np.concatenate(all_labels_target)\nall_preds_target = np.concatenate(all_preds_target)\n\n# Calculate accuracy and F1 score for each task\naccuracy_bully = accuracy_score(all_labels_bully, all_preds_bully)\nf1_bully = f1_score(all_labels_bully, all_preds_bully, average='weighted')\n\naccuracy_sentiment = accuracy_score(all_labels_sentiment, all_preds_sentiment)\nf1_sentiment = f1_score(all_labels_sentiment, all_preds_sentiment, average='weighted')\n\naccuracy_emotion = accuracy_score(all_labels_emotion, all_preds_emotion)\nf1_emotion = f1_score(all_labels_emotion, all_preds_emotion, average='weighted')\n\naccuracy_sarcasm = accuracy_score(all_labels_sarcasm, all_preds_sarcasm)\nf1_sarcasm = f1_score(all_labels_sarcasm, all_preds_sarcasm, average='weighted')\n\naccuracy_harmful_score = accuracy_score(all_labels_harmful_score, all_preds_harmful_score)\nf1_harmful_score = f1_score(all_labels_harmful_score, all_preds_harmful_score, average='weighted')\n\naccuracy_target = accuracy_score(all_labels_target, all_preds_target)\nf1_target = f1_score(all_labels_target, all_preds_target, average='weighted')\n\nprint(f'Epoch {epoch}, Validation Loss: {avg_val_loss:.4f},\\n'\n      f'Bully Accuracy: {accuracy_bully:.4f}, F1 Score: {f1_bully:.4f},\\n'\n      f'Sentiment Accuracy: {accuracy_sentiment:.4f}, F1 Score: {f1_sentiment:.4f},\\n'\n      f'Emotion Accuracy: {accuracy_emotion:.4f}, F1 Score: {f1_emotion:.4f},\\n'\n      f'Sarcasm Accuracy: {accuracy_sarcasm:.4f}, F1 Score: {f1_sarcasm:.4f},\\n'\n      f'Harmful Score Accuracy: {accuracy_harmful_score:.4f}, F1 Score: {f1_harmful_score:.4f},\\n'\n      f'Target Accuracy: {accuracy_target:.4f}, F1 Score: {f1_target:.4f}')\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:52:33.932374Z","iopub.execute_input":"2024-11-22T11:52:33.932758Z","iopub.status.idle":"2024-11-22T11:52:42.132269Z","shell.execute_reply.started":"2024-11-22T11:52:33.932719Z","shell.execute_reply":"2024-11-22T11:52:42.131216Z"}},"outputs":[{"name":"stdout","text":"Epoch 14, Validation Loss: 8.5395,\nBully Accuracy: 0.7744, F1 Score: 0.7669,\nSentiment Accuracy: 0.6299, F1 Score: 0.6479,\nEmotion Accuracy: 0.2175, F1 Score: 0.2278,\nSarcasm Accuracy: 0.5114, F1 Score: 0.3460,\nHarmful Score Accuracy: 0.9789, F1 Score: 0.9685,\nTarget Accuracy: 0.7062, F1 Score: 0.6555\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# Image_text_emotion","metadata":{}},{"cell_type":"code","source":"# Initialize the model and move it to the GPU\nmodel= Image_text_emotion()\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(model)  # Use DataParallel if multiple GPUs are available\nmodel.to(device) \noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n# Loss functions\nloss_fn_sentiment = nn.CrossEntropyLoss().to(device)\nloss_fn_emotion = nn.CrossEntropyLoss().to(device)\nloss_fn_sarcasm = nn.BCEWithLogitsLoss().to(device)\nloss_fn_bully = nn.CrossEntropyLoss().to(device)\nloss_fn_harmful_score = nn.CrossEntropyLoss().to(device)\nloss_fn_target = nn.CrossEntropyLoss().to(device)\n\n# Training loop\nfor epoch in range(15):  # Set epochs accordingly\n    model.train()\n    \n    total_loss = 0  # Initialize total loss for the epoch\n    \n    for images, text_input_ids, text_attention_mask, sentiment_labels, emotion_labels, sarcasm_labels, bully_labels, harmful_score_labels, target_labels in train_dataloader:\n        # Move data to the GPU\n    # for images, text_input_ids, text_attention_mask, bully_labels in train_dataloader:\n  \n        images = images.to(device)\n        text_input_ids = text_input_ids.to(device)\n        text_attention_mask = text_attention_mask.to(device)\n        sentiment_labels = sentiment_labels.to(device)\n        emotion_labels = emotion_labels.to(device)\n        sarcasm_labels = sarcasm_labels.to(device)\n        bully_labels = bully_labels.to(device)\n        harmful_score_labels = harmful_score_labels.to(device)\n        target_labels = target_labels.to(device)\n        \n        optimizer.zero_grad()  # Clear gradients at the start of each batch\n        \n        # Forward pass\n        sentiment_out, emotion_out, sarcasm_out, bully_out, harmful_score_out, target_out = model(images, text_input_ids, text_attention_mask)\n        \n        # Compute loss for each task\n        loss_sentiment = loss_fn_sentiment(sentiment_out, sentiment_labels)\n        loss_emotion = loss_fn_emotion(emotion_out, emotion_labels)\n        loss_sarcasm = loss_fn_sarcasm(sarcasm_out.squeeze(), sarcasm_labels.float())  # Squeeze if necessary\n        loss_bully = loss_fn_bully(bully_out, bully_labels)\n        loss_harmful_score = loss_fn_harmful_score(harmful_score_out, harmful_score_labels)\n        loss_target = loss_fn_target(target_out, target_labels)\n        \n        # Total loss (sum or weigh the losses as needed)\n        total_loss_batch = loss_sentiment + loss_emotion + loss_sarcasm + loss_bully + loss_harmful_score + loss_target\n        \n        # Backward pass and optimization\n        total_loss_batch.backward()\n        optimizer.step()  # Update model parameters\n        \n        total_loss += total_loss_batch.item()  # Accumulate loss for the epoch\n\n    # Optionally clear cache at the end of each epoch\n    torch.cuda.empty_cache()  \n    \n    # Print the average loss for the epoch\n    avg_loss = total_loss / len(train_dataloader)\n    print(f'Epoch {epoch}, Average Loss: {avg_loss:.4f}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T11:52:42.134521Z","iopub.execute_input":"2024-11-22T11:52:42.135233Z","iopub.status.idle":"2024-11-22T12:11:40.770927Z","shell.execute_reply.started":"2024-11-22T11:52:42.135197Z","shell.execute_reply":"2024-11-22T12:11:40.769939Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0, Average Loss: 4.7081\nEpoch 1, Average Loss: 4.3522\nEpoch 2, Average Loss: 3.9955\nEpoch 3, Average Loss: 3.4775\nEpoch 4, Average Loss: 3.0103\nEpoch 5, Average Loss: 2.6499\nEpoch 6, Average Loss: 2.3585\nEpoch 7, Average Loss: 2.1452\nEpoch 8, Average Loss: 2.0362\nEpoch 9, Average Loss: 1.8962\nEpoch 10, Average Loss: 1.7373\nEpoch 11, Average Loss: 1.7050\nEpoch 12, Average Loss: 1.6027\nEpoch 13, Average Loss: 1.5829\nEpoch 14, Average Loss: 1.5226\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Import required libraries (if not already done)\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, f1_score\n\n# Validation phase\nmodel.eval()  # Set model to evaluation mode\ntotal_val_loss = 0\n\n# Initialize lists to store true and predicted labels for each task\nall_labels_bully = []\nall_preds_bully = []\n\nall_labels_sentiment = []\nall_preds_sentiment = []\n\nall_labels_emotion = []\nall_preds_emotion = []\n\nall_labels_sarcasm = []\nall_preds_sarcasm = []\n\nall_labels_harmful_score = []\nall_preds_harmful_score = []\n\nall_labels_target = []\nall_preds_target = []\n\nwith torch.no_grad():  # Disable gradient calculation\n    for images, text_input_ids, text_attention_mask, sentiment_labels, emotion_labels, sarcasm_labels, bully_labels, harmful_score_labels, target_labels in val_dataloader:\n        # Move data to the GPU\n        images = images.to(device)\n        text_input_ids = text_input_ids.to(device)\n        text_attention_mask = text_attention_mask.to(device)\n        sentiment_labels = sentiment_labels.to(device)\n        emotion_labels = emotion_labels.to(device)\n        sarcasm_labels = sarcasm_labels.to(device)\n        bully_labels = bully_labels.to(device)\n        harmful_score_labels = harmful_score_labels.to(device)\n        target_labels = target_labels.to(device)\n\n        # Forward pass\n        sentiment_out, emotion_out, sarcasm_out, bully_out, harmful_score_out, target_out = model(images, text_input_ids, text_attention_mask)\n\n        # Compute loss for each task\n        loss_sentiment = loss_fn_sentiment(sentiment_out, sentiment_labels)\n        loss_emotion = loss_fn_emotion(emotion_out, emotion_labels)\n        loss_sarcasm = loss_fn_sarcasm(sarcasm_out.squeeze(), sarcasm_labels.float())\n        loss_bully = loss_fn_bully(bully_out, bully_labels)\n        loss_harmful_score = loss_fn_harmful_score(harmful_score_out, harmful_score_labels)\n        loss_target = loss_fn_target(target_out, target_labels)\n\n        # Total loss\n        total_val_loss += (loss_sentiment + loss_emotion + loss_sarcasm + loss_bully + loss_harmful_score + loss_target).item()\n\n        # Get predictions for each task\n        _, predicted_sentiment = torch.max(sentiment_out, 1)\n        _, predicted_emotion = torch.max(emotion_out, 1)\n        _, predicted_sarcasm = torch.max(sarcasm_out, 1)\n        _, predicted_bully = torch.max(bully_out, 1)\n        _, predicted_harmful_score = torch.max(harmful_score_out, 1)  # Assuming multi-class\n        _, predicted_target = torch.max(target_out, 1)  # Assuming multi-class\n\n        # Collect true and predicted labels for each task\n        all_labels_sentiment.append(sentiment_labels.cpu().numpy())\n        all_preds_sentiment.append(predicted_sentiment.cpu().numpy())\n\n        all_labels_emotion.append(emotion_labels.cpu().numpy())\n        all_preds_emotion.append(predicted_emotion.cpu().numpy())\n\n        all_labels_sarcasm.append(sarcasm_labels.cpu().numpy())\n        all_preds_sarcasm.append(predicted_sarcasm.cpu().numpy())\n\n        all_labels_bully.append(bully_labels.cpu().numpy())\n        all_preds_bully.append(predicted_bully.cpu().numpy())\n\n        all_labels_harmful_score.append(harmful_score_labels.cpu().numpy())\n        all_preds_harmful_score.append(predicted_harmful_score.cpu().numpy())\n\n        all_labels_target.append(target_labels.cpu().numpy())\n        all_preds_target.append(predicted_target.cpu().numpy())\n\navg_val_loss = total_val_loss / len(val_dataloader)\n\n# Flatten lists for each task\nall_labels_bully = np.concatenate(all_labels_bully)\nall_preds_bully = np.concatenate(all_preds_bully)\n\nall_labels_sentiment = np.concatenate(all_labels_sentiment)\nall_preds_sentiment = np.concatenate(all_preds_sentiment)\n\nall_labels_emotion = np.concatenate(all_labels_emotion)\nall_preds_emotion = np.concatenate(all_preds_emotion)\n\nall_labels_sarcasm = np.concatenate(all_labels_sarcasm)\nall_preds_sarcasm = np.concatenate(all_preds_sarcasm)\n\nall_labels_harmful_score = np.concatenate(all_labels_harmful_score)\nall_preds_harmful_score = np.concatenate(all_preds_harmful_score)\n\nall_labels_target = np.concatenate(all_labels_target)\nall_preds_target = np.concatenate(all_preds_target)\n\n# Calculate accuracy and F1 score for each task\naccuracy_bully_em = accuracy_score(all_labels_bully, all_preds_bully)\nf1_bully_em = f1_score(all_labels_bully, all_preds_bully, average='weighted')\n\naccuracy_sentiment_em = accuracy_score(all_labels_sentiment, all_preds_sentiment)\nf1_sentiment_em = f1_score(all_labels_sentiment, all_preds_sentiment, average='weighted')\n\naccuracy_emotion_em = accuracy_score(all_labels_emotion, all_preds_emotion)\nf1_emotion_em = f1_score(all_labels_emotion, all_preds_emotion, average='weighted')\n\naccuracy_sarcasm_em = accuracy_score(all_labels_sarcasm, all_preds_sarcasm)\nf1_sarcasm_em = f1_score(all_labels_sarcasm, all_preds_sarcasm, average='weighted')\n\naccuracy_harmful_score_em = accuracy_score(all_labels_harmful_score, all_preds_harmful_score)\nf1_harmful_score_em = f1_score(all_labels_harmful_score, all_preds_harmful_score, average='weighted')\n\naccuracy_target_em = accuracy_score(all_labels_target, all_preds_target)\nf1_target_em = f1_score(all_labels_target, all_preds_target, average='weighted')\n\nprint(f'Epoch {epoch}, Validation Loss: {avg_val_loss:.4f},\\n'\n      f'Bully Accuracy: {accuracy_bully:.4f}, F1 Score: {f1_bully:.4f},\\n'\n      f'Sentiment Accuracy: {accuracy_sentiment:.4f}, F1 Score: {f1_sentiment:.4f},\\n'\n      f'Emotion Accuracy: {accuracy_emotion:.4f}, F1 Score: {f1_emotion:.4f},\\n'\n      f'Sarcasm Accuracy: {accuracy_sarcasm:.4f}, F1 Score: {f1_sarcasm:.4f},\\n'\n      f'Harmful Score Accuracy: {accuracy_harmful_score:.4f}, F1 Score: {f1_harmful_score:.4f},\\n'\n      f'Target Accuracy: {accuracy_target:.4f}, F1 Score: {f1_target:.4f}')\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:11:40.772293Z","iopub.execute_input":"2024-11-22T12:11:40.772599Z","iopub.status.idle":"2024-11-22T12:11:49.029001Z","shell.execute_reply.started":"2024-11-22T12:11:40.772572Z","shell.execute_reply":"2024-11-22T12:11:49.028108Z"}},"outputs":[{"name":"stdout","text":"Epoch 14, Validation Loss: 8.0432,\nBully Accuracy: 0.7744, F1 Score: 0.7669,\nSentiment Accuracy: 0.6299, F1 Score: 0.6479,\nEmotion Accuracy: 0.2175, F1 Score: 0.2278,\nSarcasm Accuracy: 0.5114, F1 Score: 0.3460,\nHarmful Score Accuracy: 0.9789, F1 Score: 0.9685,\nTarget Accuracy: 0.7062, F1 Score: 0.6555\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# Image_text_sentiment","metadata":{}},{"cell_type":"code","source":"# Initialize the model and move it to the GPU\nmodel= Image_text_sentiment()\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(model)  # Use DataParallel if multiple GPUs are available\nmodel.to(device) \noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n# Loss functions\nloss_fn_sentiment = nn.CrossEntropyLoss().to(device)\nloss_fn_emotion = nn.CrossEntropyLoss().to(device)\nloss_fn_sarcasm = nn.BCEWithLogitsLoss().to(device)\nloss_fn_bully = nn.CrossEntropyLoss().to(device)\nloss_fn_harmful_score = nn.CrossEntropyLoss().to(device)\nloss_fn_target = nn.CrossEntropyLoss().to(device)\n\n# Training loop\nfor epoch in range(15):  # Set epochs accordingly\n    model.train()\n    \n    total_loss = 0  # Initialize total loss for the epoch\n    \n    for images, text_input_ids, text_attention_mask, sentiment_labels, emotion_labels, sarcasm_labels, bully_labels, harmful_score_labels, target_labels in train_dataloader:\n        # Move data to the GPU\n    # for images, text_input_ids, text_attention_mask, bully_labels in train_dataloader:\n  \n        images = images.to(device)\n        text_input_ids = text_input_ids.to(device)\n        text_attention_mask = text_attention_mask.to(device)\n        sentiment_labels = sentiment_labels.to(device)\n        emotion_labels = emotion_labels.to(device)\n        sarcasm_labels = sarcasm_labels.to(device)\n        bully_labels = bully_labels.to(device)\n        harmful_score_labels = harmful_score_labels.to(device)\n        target_labels = target_labels.to(device)\n        \n        optimizer.zero_grad()  # Clear gradients at the start of each batch\n        \n        # Forward pass\n        sentiment_out, emotion_out, sarcasm_out, bully_out, harmful_score_out, target_out = model(images, text_input_ids, text_attention_mask)\n        \n        # Compute loss for each task\n        loss_sentiment = loss_fn_sentiment(sentiment_out, sentiment_labels)\n        loss_emotion = loss_fn_emotion(emotion_out, emotion_labels)\n        loss_sarcasm = loss_fn_sarcasm(sarcasm_out.squeeze(), sarcasm_labels.float())  # Squeeze if necessary\n        loss_bully = loss_fn_bully(bully_out, bully_labels)\n        loss_harmful_score = loss_fn_harmful_score(harmful_score_out, harmful_score_labels)\n        loss_target = loss_fn_target(target_out, target_labels)\n        \n        # Total loss (sum or weigh the losses as needed)\n        total_loss_batch = loss_sentiment + loss_emotion + loss_sarcasm + loss_bully + loss_harmful_score + loss_target\n        \n        # Backward pass and optimization\n        total_loss_batch.backward()\n        optimizer.step()  # Update model parameters\n        \n        total_loss += total_loss_batch.item()  # Accumulate loss for the epoch\n\n    # Optionally clear cache at the end of each epoch\n    torch.cuda.empty_cache()  \n    \n    # Print the average loss for the epoch\n    avg_loss = total_loss / len(train_dataloader)\n    print(f'Epoch {epoch}, Average Loss: {avg_loss:.4f}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:11:49.031512Z","iopub.execute_input":"2024-11-22T12:11:49.032152Z","iopub.status.idle":"2024-11-22T12:30:45.237213Z","shell.execute_reply.started":"2024-11-22T12:11:49.032123Z","shell.execute_reply":"2024-11-22T12:30:45.236002Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0, Average Loss: 4.7218\nEpoch 1, Average Loss: 4.3478\nEpoch 2, Average Loss: 4.0018\nEpoch 3, Average Loss: 3.4995\nEpoch 4, Average Loss: 3.0654\nEpoch 5, Average Loss: 2.6763\nEpoch 6, Average Loss: 2.4189\nEpoch 7, Average Loss: 2.2007\nEpoch 8, Average Loss: 2.0683\nEpoch 9, Average Loss: 1.8804\nEpoch 10, Average Loss: 1.8753\nEpoch 11, Average Loss: 1.7336\nEpoch 12, Average Loss: 1.6399\nEpoch 13, Average Loss: 1.5704\nEpoch 14, Average Loss: 1.5171\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Import required libraries (if not already done)\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, f1_score\n\n# Validation phase\nmodel.eval()  # Set model to evaluation mode\ntotal_val_loss = 0\n\n# Initialize lists to store true and predicted labels for each task\nall_labels_bully = []\nall_preds_bully = []\n\nall_labels_sentiment = []\nall_preds_sentiment = []\n\nall_labels_emotion = []\nall_preds_emotion = []\n\nall_labels_sarcasm = []\nall_preds_sarcasm = []\n\nall_labels_harmful_score = []\nall_preds_harmful_score = []\n\nall_labels_target = []\nall_preds_target = []\n\nwith torch.no_grad():  # Disable gradient calculation\n    for images, text_input_ids, text_attention_mask, sentiment_labels, emotion_labels, sarcasm_labels, bully_labels, harmful_score_labels, target_labels in val_dataloader:\n        # Move data to the GPU\n        images = images.to(device)\n        text_input_ids = text_input_ids.to(device)\n        text_attention_mask = text_attention_mask.to(device)\n        sentiment_labels = sentiment_labels.to(device)\n        emotion_labels = emotion_labels.to(device)\n        sarcasm_labels = sarcasm_labels.to(device)\n        bully_labels = bully_labels.to(device)\n        harmful_score_labels = harmful_score_labels.to(device)\n        target_labels = target_labels.to(device)\n\n        # Forward pass\n        sentiment_out, emotion_out, sarcasm_out, bully_out, harmful_score_out, target_out = model(images, text_input_ids, text_attention_mask)\n\n        # Compute loss for each task\n        loss_sentiment = loss_fn_sentiment(sentiment_out, sentiment_labels)\n        loss_emotion = loss_fn_emotion(emotion_out, emotion_labels)\n        loss_sarcasm = loss_fn_sarcasm(sarcasm_out.squeeze(), sarcasm_labels.float())\n        loss_bully = loss_fn_bully(bully_out, bully_labels)\n        loss_harmful_score = loss_fn_harmful_score(harmful_score_out, harmful_score_labels)\n        loss_target = loss_fn_target(target_out, target_labels)\n\n        # Total loss\n        total_val_loss += (loss_sentiment + loss_emotion + loss_sarcasm + loss_bully + loss_harmful_score + loss_target).item()\n\n        # Get predictions for each task\n        _, predicted_sentiment = torch.max(sentiment_out, 1)\n        _, predicted_emotion = torch.max(emotion_out, 1)\n        _, predicted_sarcasm = torch.max(sarcasm_out, 1)\n        _, predicted_bully = torch.max(bully_out, 1)\n        _, predicted_harmful_score = torch.max(harmful_score_out, 1)  # Assuming multi-class\n        _, predicted_target = torch.max(target_out, 1)  # Assuming multi-class\n\n        # Collect true and predicted labels for each task\n        all_labels_sentiment.append(sentiment_labels.cpu().numpy())\n        all_preds_sentiment.append(predicted_sentiment.cpu().numpy())\n\n        all_labels_emotion.append(emotion_labels.cpu().numpy())\n        all_preds_emotion.append(predicted_emotion.cpu().numpy())\n\n        all_labels_sarcasm.append(sarcasm_labels.cpu().numpy())\n        all_preds_sarcasm.append(predicted_sarcasm.cpu().numpy())\n\n        all_labels_bully.append(bully_labels.cpu().numpy())\n        all_preds_bully.append(predicted_bully.cpu().numpy())\n\n        all_labels_harmful_score.append(harmful_score_labels.cpu().numpy())\n        all_preds_harmful_score.append(predicted_harmful_score.cpu().numpy())\n\n        all_labels_target.append(target_labels.cpu().numpy())\n        all_preds_target.append(predicted_target.cpu().numpy())\n\navg_val_loss = total_val_loss / len(val_dataloader)\n\n# Flatten lists for each task\nall_labels_bully = np.concatenate(all_labels_bully)\nall_preds_bully = np.concatenate(all_preds_bully)\n\nall_labels_sentiment = np.concatenate(all_labels_sentiment)\nall_preds_sentiment = np.concatenate(all_preds_sentiment)\n\nall_labels_emotion = np.concatenate(all_labels_emotion)\nall_preds_emotion = np.concatenate(all_preds_emotion)\n\nall_labels_sarcasm = np.concatenate(all_labels_sarcasm)\nall_preds_sarcasm = np.concatenate(all_preds_sarcasm)\n\nall_labels_harmful_score = np.concatenate(all_labels_harmful_score)\nall_preds_harmful_score = np.concatenate(all_preds_harmful_score)\n\nall_labels_target = np.concatenate(all_labels_target)\nall_preds_target = np.concatenate(all_preds_target)\n\n# Calculate accuracy and F1 score for each task\naccuracy_bully_SA = accuracy_score(all_labels_bully, all_preds_bully)\nf1_bully_SA = f1_score(all_labels_bully, all_preds_bully, average='weighted')\n\naccuracy_sentiment_SA = accuracy_score(all_labels_sentiment, all_preds_sentiment)\nf1_sentiment_SA = f1_score(all_labels_sentiment, all_preds_sentiment, average='weighted')\n\naccuracy_emotion_SA = accuracy_score(all_labels_emotion, all_preds_emotion)\nf1_emotion_SA = f1_score(all_labels_emotion, all_preds_emotion, average='weighted')\n\naccuracy_sarcasm_SA = accuracy_score(all_labels_sarcasm, all_preds_sarcasm)\nf1_sarcasm_SA = f1_score(all_labels_sarcasm, all_preds_sarcasm, average='weighted')\n\naccuracy_harmful_score_SA = accuracy_score(all_labels_harmful_score, all_preds_harmful_score)\nf1_harmful_score_SA = f1_score(all_labels_harmful_score, all_preds_harmful_score, average='weighted')\n\naccuracy_target_SA = accuracy_score(all_labels_target, all_preds_target)\nf1_target_SA = f1_score(all_labels_target, all_preds_target, average='weighted')\n\nprint(f'Epoch {epoch}, Validation Loss: {avg_val_loss:.4f},\\n'\n      f'Bully Accuracy: {accuracy_bully:.4f}, F1 Score: {f1_bully:.4f},\\n'\n      f'Sentiment Accuracy: {accuracy_sentiment:.4f}, F1 Score: {f1_sentiment:.4f},\\n'\n      f'Emotion Accuracy: {accuracy_emotion:.4f}, F1 Score: {f1_emotion:.4f},\\n'\n      f'Sarcasm Accuracy: {accuracy_sarcasm:.4f}, F1 Score: {f1_sarcasm:.4f},\\n'\n      f'Harmful Score Accuracy: {accuracy_harmful_score:.4f}, F1 Score: {f1_harmful_score:.4f},\\n'\n      f'Target Accuracy: {accuracy_target:.4f}, F1 Score: {f1_target:.4f}')\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:30:45.239033Z","iopub.execute_input":"2024-11-22T12:30:45.239633Z","iopub.status.idle":"2024-11-22T12:30:53.353760Z","shell.execute_reply.started":"2024-11-22T12:30:45.239589Z","shell.execute_reply":"2024-11-22T12:30:53.352688Z"}},"outputs":[{"name":"stdout","text":"Epoch 14, Validation Loss: 8.2057,\nBully Accuracy: 0.7744, F1 Score: 0.7669,\nSentiment Accuracy: 0.6299, F1 Score: 0.6479,\nEmotion Accuracy: 0.2175, F1 Score: 0.2278,\nSarcasm Accuracy: 0.5114, F1 Score: 0.3460,\nHarmful Score Accuracy: 0.9789, F1 Score: 0.9685,\nTarget Accuracy: 0.7062, F1 Score: 0.6555\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# Image_text_emotion sentiment","metadata":{}},{"cell_type":"code","source":"# Initialize the model and move it to the GPU\nmodel= Image_text_emotion_sentiment()\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(model)  # Use DataParallel if multiple GPUs are available\nmodel.to(device) \noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n# Loss functions\nloss_fn_sentiment = nn.CrossEntropyLoss().to(device)\nloss_fn_emotion = nn.CrossEntropyLoss().to(device)\nloss_fn_sarcasm = nn.BCEWithLogitsLoss().to(device)\nloss_fn_bully = nn.CrossEntropyLoss().to(device)\nloss_fn_harmful_score = nn.CrossEntropyLoss().to(device)\nloss_fn_target = nn.CrossEntropyLoss().to(device)\n\n# Training loop\nfor epoch in range(15):  # Set epochs accordingly\n    model.train()\n    \n    total_loss = 0  # Initialize total loss for the epoch\n    \n    for images, text_input_ids, text_attention_mask, sentiment_labels, emotion_labels, sarcasm_labels, bully_labels, harmful_score_labels, target_labels in train_dataloader:\n        # Move data to the GPU\n    # for images, text_input_ids, text_attention_mask, bully_labels in train_dataloader:\n  \n        images = images.to(device)\n        text_input_ids = text_input_ids.to(device)\n        text_attention_mask = text_attention_mask.to(device)\n        sentiment_labels = sentiment_labels.to(device)\n        emotion_labels = emotion_labels.to(device)\n        sarcasm_labels = sarcasm_labels.to(device)\n        bully_labels = bully_labels.to(device)\n        harmful_score_labels = harmful_score_labels.to(device)\n        target_labels = target_labels.to(device)\n        \n        optimizer.zero_grad()  # Clear gradients at the start of each batch\n        \n        # Forward pass\n        sentiment_out, emotion_out, sarcasm_out, bully_out, harmful_score_out, target_out = model(images, text_input_ids, text_attention_mask)\n        \n        # Compute loss for each task\n        loss_sentiment = loss_fn_sentiment(sentiment_out, sentiment_labels)\n        loss_emotion = loss_fn_emotion(emotion_out, emotion_labels)\n        loss_sarcasm = loss_fn_sarcasm(sarcasm_out.squeeze(), sarcasm_labels.float())  # Squeeze if necessary\n        loss_bully = loss_fn_bully(bully_out, bully_labels)\n        loss_harmful_score = loss_fn_harmful_score(harmful_score_out, harmful_score_labels)\n        loss_target = loss_fn_target(target_out, target_labels)\n        \n        # Total loss (sum or weigh the losses as needed)\n        total_loss_batch = loss_sentiment + loss_emotion + loss_sarcasm + loss_bully + loss_harmful_score + loss_target\n        \n        # Backward pass and optimization\n        total_loss_batch.backward()\n        optimizer.step()  # Update model parameters\n        \n        total_loss += total_loss_batch.item()  # Accumulate loss for the epoch\n\n    # Optionally clear cache at the end of each epoch\n    torch.cuda.empty_cache()  \n    \n    # Print the average loss for the epoch\n    avg_loss = total_loss / len(train_dataloader)\n    print(f'Epoch {epoch}, Average Loss: {avg_loss:.4f}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:30:53.355036Z","iopub.execute_input":"2024-11-22T12:30:53.355358Z","iopub.status.idle":"2024-11-22T12:49:50.615104Z","shell.execute_reply.started":"2024-11-22T12:30:53.355327Z","shell.execute_reply":"2024-11-22T12:49:50.614211Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0, Average Loss: 4.7302\nEpoch 1, Average Loss: 4.3580\nEpoch 2, Average Loss: 4.0041\nEpoch 3, Average Loss: 3.5066\nEpoch 4, Average Loss: 3.0784\nEpoch 5, Average Loss: 2.6493\nEpoch 6, Average Loss: 2.4539\nEpoch 7, Average Loss: 2.2440\nEpoch 8, Average Loss: 2.0973\nEpoch 9, Average Loss: 1.9535\nEpoch 10, Average Loss: 1.8408\nEpoch 11, Average Loss: 1.8069\nEpoch 12, Average Loss: 1.6760\nEpoch 13, Average Loss: 1.6009\nEpoch 14, Average Loss: 1.5619\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Import required libraries (if not already done)\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, f1_score\n\n# Validation phase\nmodel.eval()  # Set model to evaluation mode\ntotal_val_loss = 0\n\n# Initialize lists to store true and predicted labels for each task\nall_labels_bully = []\nall_preds_bully = []\n\nall_labels_sentiment = []\nall_preds_sentiment = []\n\nall_labels_emotion = []\nall_preds_emotion = []\n\nall_labels_sarcasm = []\nall_preds_sarcasm = []\n\nall_labels_harmful_score = []\nall_preds_harmful_score = []\n\nall_labels_target = []\nall_preds_target = []\n\nwith torch.no_grad():  # Disable gradient calculation\n    for images, text_input_ids, text_attention_mask, sentiment_labels, emotion_labels, sarcasm_labels, bully_labels, harmful_score_labels, target_labels in val_dataloader:\n        # Move data to the GPU\n        images = images.to(device)\n        text_input_ids = text_input_ids.to(device)\n        text_attention_mask = text_attention_mask.to(device)\n        sentiment_labels = sentiment_labels.to(device)\n        emotion_labels = emotion_labels.to(device)\n        sarcasm_labels = sarcasm_labels.to(device)\n        bully_labels = bully_labels.to(device)\n        harmful_score_labels = harmful_score_labels.to(device)\n        target_labels = target_labels.to(device)\n\n        # Forward pass\n        sentiment_out, emotion_out, sarcasm_out, bully_out, harmful_score_out, target_out = model(images, text_input_ids, text_attention_mask)\n\n        # Compute loss for each task\n        loss_sentiment = loss_fn_sentiment(sentiment_out, sentiment_labels)\n        loss_emotion = loss_fn_emotion(emotion_out, emotion_labels)\n        loss_sarcasm = loss_fn_sarcasm(sarcasm_out.squeeze(), sarcasm_labels.float())\n        loss_bully = loss_fn_bully(bully_out, bully_labels)\n        loss_harmful_score = loss_fn_harmful_score(harmful_score_out, harmful_score_labels)\n        loss_target = loss_fn_target(target_out, target_labels)\n\n        # Total loss\n        total_val_loss += (loss_sentiment + loss_emotion + loss_sarcasm + loss_bully + loss_harmful_score + loss_target).item()\n\n        # Get predictions for each task\n        _, predicted_sentiment = torch.max(sentiment_out, 1)\n        _, predicted_emotion = torch.max(emotion_out, 1)\n        _, predicted_sarcasm = torch.max(sarcasm_out, 1)\n        _, predicted_bully = torch.max(bully_out, 1)\n        _, predicted_harmful_score = torch.max(harmful_score_out, 1)  # Assuming multi-class\n        _, predicted_target = torch.max(target_out, 1)  # Assuming multi-class\n\n        # Collect true and predicted labels for each task\n        all_labels_sentiment.append(sentiment_labels.cpu().numpy())\n        all_preds_sentiment.append(predicted_sentiment.cpu().numpy())\n\n        all_labels_emotion.append(emotion_labels.cpu().numpy())\n        all_preds_emotion.append(predicted_emotion.cpu().numpy())\n\n        all_labels_sarcasm.append(sarcasm_labels.cpu().numpy())\n        all_preds_sarcasm.append(predicted_sarcasm.cpu().numpy())\n\n        all_labels_bully.append(bully_labels.cpu().numpy())\n        all_preds_bully.append(predicted_bully.cpu().numpy())\n\n        all_labels_harmful_score.append(harmful_score_labels.cpu().numpy())\n        all_preds_harmful_score.append(predicted_harmful_score.cpu().numpy())\n\n        all_labels_target.append(target_labels.cpu().numpy())\n        all_preds_target.append(predicted_target.cpu().numpy())\n\navg_val_loss = total_val_loss / len(val_dataloader)\n\n# Flatten lists for each task\nall_labels_bully = np.concatenate(all_labels_bully)\nall_preds_bully = np.concatenate(all_preds_bully)\n\nall_labels_sentiment = np.concatenate(all_labels_sentiment)\nall_preds_sentiment = np.concatenate(all_preds_sentiment)\n\nall_labels_emotion = np.concatenate(all_labels_emotion)\nall_preds_emotion = np.concatenate(all_preds_emotion)\n\nall_labels_sarcasm = np.concatenate(all_labels_sarcasm)\nall_preds_sarcasm = np.concatenate(all_preds_sarcasm)\n\nall_labels_harmful_score = np.concatenate(all_labels_harmful_score)\nall_preds_harmful_score = np.concatenate(all_preds_harmful_score)\n\nall_labels_target = np.concatenate(all_labels_target)\nall_preds_target = np.concatenate(all_preds_target)\n\n# Calculate accuracy and F1 score for each task\naccuracy_bully_SA_EM = accuracy_score(all_labels_bully, all_preds_bully)\nf1_bully_SA_EM = f1_score(all_labels_bully, all_preds_bully, average='weighted')\n\naccuracy_sentiment_SA_EM = accuracy_score(all_labels_sentiment, all_preds_sentiment)\nf1_sentiment_SA_EM = f1_score(all_labels_sentiment, all_preds_sentiment, average='weighted')\n\naccuracy_emotion_SA_EM = accuracy_score(all_labels_emotion, all_preds_emotion)\nf1_emotion_SA_EM = f1_score(all_labels_emotion, all_preds_emotion, average='weighted')\n\naccuracy_sarcasm_SA_EM = accuracy_score(all_labels_sarcasm, all_preds_sarcasm)\nf1_sarcasm_SA_EM = f1_score(all_labels_sarcasm, all_preds_sarcasm, average='weighted')\n\naccuracy_harmful_score_SA_EM = accuracy_score(all_labels_harmful_score, all_preds_harmful_score)\nf1_harmful_score_SA_EM = f1_score(all_labels_harmful_score, all_preds_harmful_score, average='weighted')\n\naccuracy_target_SA_EM = accuracy_score(all_labels_target, all_preds_target)\nf1_target_SA_EM = f1_score(all_labels_target, all_preds_target, average='weighted')\n\nprint(f'Epoch {epoch}, Validation Loss: {avg_val_loss:.4f},\\n'\n      f'Bully Accuracy: {accuracy_bully:.4f}, F1 Score: {f1_bully:.4f},\\n'\n      f'Sentiment Accuracy: {accuracy_sentiment:.4f}, F1 Score: {f1_sentiment:.4f},\\n'\n      f'Emotion Accuracy: {accuracy_emotion:.4f}, F1 Score: {f1_emotion:.4f},\\n'\n      f'Sarcasm Accuracy: {accuracy_sarcasm:.4f}, F1 Score: {f1_sarcasm:.4f},\\n'\n      f'Harmful Score Accuracy: {accuracy_harmful_score:.4f}, F1 Score: {f1_harmful_score:.4f},\\n'\n      f'Target Accuracy: {accuracy_target:.4f}, F1 Score: {f1_target:.4f}')\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:49:50.616543Z","iopub.execute_input":"2024-11-22T12:49:50.616835Z","iopub.status.idle":"2024-11-22T12:49:58.836865Z","shell.execute_reply.started":"2024-11-22T12:49:50.616808Z","shell.execute_reply":"2024-11-22T12:49:58.835990Z"}},"outputs":[{"name":"stdout","text":"Epoch 14, Validation Loss: 8.8220,\nBully Accuracy: 0.7744, F1 Score: 0.7669,\nSentiment Accuracy: 0.6299, F1 Score: 0.6479,\nEmotion Accuracy: 0.2175, F1 Score: 0.2278,\nSarcasm Accuracy: 0.5114, F1 Score: 0.3460,\nHarmful Score Accuracy: 0.9789, F1 Score: 0.9685,\nTarget Accuracy: 0.7062, F1 Score: 0.6555\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"accuracy_target_EM","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:00:50.933199Z","iopub.execute_input":"2024-11-22T13:00:50.933524Z","iopub.status.idle":"2024-11-22T13:00:50.956880Z","shell.execute_reply.started":"2024-11-22T13:00:50.933497Z","shell.execute_reply":"2024-11-22T13:00:50.955836Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maccuracy_target_EM\u001b[49m\n","\u001b[0;31mNameError\u001b[0m: name 'accuracy_target_EM' is not defined"],"ename":"NameError","evalue":"name 'accuracy_target_EM' is not defined","output_type":"error"}],"execution_count":34},{"cell_type":"code","source":"accuracy_target_SA","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:01:22.574660Z","iopub.execute_input":"2024-11-22T13:01:22.575302Z","iopub.status.idle":"2024-11-22T13:01:22.580450Z","shell.execute_reply.started":"2024-11-22T13:01:22.575270Z","shell.execute_reply":"2024-11-22T13:01:22.579589Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"0.7159090909090909"},"metadata":{}}],"execution_count":37},{"cell_type":"raw","source":"accuracy_target","metadata":{}},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:58:54.062889Z","iopub.execute_input":"2024-11-22T12:58:54.063306Z","iopub.status.idle":"2024-11-22T12:58:54.067448Z","shell.execute_reply.started":"2024-11-22T12:58:54.063261Z","shell.execute_reply":"2024-11-22T12:58:54.066446Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"fi","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}